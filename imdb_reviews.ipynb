{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    }
   ],
   "source": [
    "import trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax import layers as tl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/prhyme/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46753c9e532d4424b9240a44b641abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444253fbfcdf47c5a67eac9c4fb662ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Size...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c739d51b034d2583981f5c22f3188c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/prhyme/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete48N9DN/imdb_reviews-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663535edf2b54497a2e357e92b8372ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dc819ad6af49b09ad2da17a2fb2ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/prhyme/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete48N9DN/imdb_reviews-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fb292a6f2e4cfa81fa558c0af19c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a191d518364de083e8c02c0fcca4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/prhyme/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete48N9DN/imdb_reviews-unsupervised.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570bf59da8bd4161902166e6d145ed59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/prhyme/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_stream = trax.data.TFDS('imdb_reviews', keys=('text','label'), train=True)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stream = trax.data.TFDS('imdb_reviews', keys=('text','label'), train=False)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(\n",
    "    trax.data.Tokenize(vocab_file='en_8k.subword',keys=[0]),\n",
    "    trax.data.Shuffle(),\n",
    "    trax.data.FilterByLength(max_length=2048, length_keys=[0]),\n",
    "    trax.data.BucketByLength(boundaries=[32, 128, 512, 2048],\n",
    "                            batch_sizes=[512,128,32,8,1],\n",
    "                            length_keys=[0]),\n",
    "    trax.data.AddLossWeights()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches_stream = data_pipeline(train_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batches_stream = data_pipeline(eval_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(train_batches_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes=[(8, 2048), (8,), (8,)]\n"
     ]
    }
   ],
   "source": [
    "print(f'shapes={[x.shape for x in example_batch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tl.Serial(\n",
    "    tl.Embedding(vocab_size=8192, d_feature=256),\n",
    "    tl.Mean(axis=1),\n",
    "    tl.Dense(2),\n",
    "    tl.LogSoftmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prhyme/.local/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_batches_stream,\n",
    "    loss_layer=tl.CrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_task = training.EvalTask(\n",
    "    labeled_data=eval_batches_stream,\n",
    "    metrics = [tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "    n_eval_batches=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop saves checkpoints to output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.expanduser('~/output_dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop = training.Loop(model,\n",
    "                             train_task,\n",
    "                             eval_tasks=[eval_task],\n",
    "                             output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Ran 1 train steps in 2.08 secs\n",
      "Step      1: train CrossEntropyLoss |  0.69912976\n",
      "Step      1: eval  CrossEntropyLoss |  0.70418198\n",
      "Step      1: eval          Accuracy |  0.46406250\n",
      "\n",
      "Step    500: Ran 499 train steps in 17.23 secs\n",
      "Step    500: train CrossEntropyLoss |  0.49487442\n",
      "Step    500: eval  CrossEntropyLoss |  0.40184160\n",
      "Step    500: eval          Accuracy |  0.84375000\n",
      "\n",
      "Step   1000: Ran 500 train steps in 14.92 secs\n",
      "Step   1000: train CrossEntropyLoss |  0.35941410\n",
      "Step   1000: eval  CrossEntropyLoss |  0.47291508\n",
      "Step   1000: eval          Accuracy |  0.78281250\n",
      "\n",
      "Step   1500: Ran 500 train steps in 16.19 secs\n",
      "Step   1500: train CrossEntropyLoss |  0.33607489\n",
      "Step   1500: eval  CrossEntropyLoss |  0.30258615\n",
      "Step   1500: eval          Accuracy |  0.87343750\n",
      "\n",
      "Step   2000: Ran 500 train steps in 15.87 secs\n",
      "Step   2000: train CrossEntropyLoss |  0.28492057\n",
      "Step   2000: eval  CrossEntropyLoss |  0.41767745\n",
      "Step   2000: eval          Accuracy |  0.80625000\n"
     ]
    }
   ],
   "source": [
    "training_loop.run(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = next(eval_batches_stream)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_str = trax.data.detokenize(example_input, vocab_file='en_8k.subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of Chaplin\\'s longest films up to that point, Burlesque on Carmen is a clever and surprisingly complex parody of what was then \"Prosper Merimee\\'s\" well-known story about \"Carmen.\" I was a little confused about the difference between the IMDb\\'s listing of the 1915 Burlesque on Carmen and the 1916 version. Based on the running time I assume that it was the 1915 version that I saw, since the 1916 one is a good 20 minutes longer, and from what I\\'ve read, those are 20 unnecessary and unimpressive minutes. <br /><br />From the very beginning, it\\'s clear that Burlesque on Carmen is one of Chaplin\\'s most complex and ambitious efforts to date, starting off with a long back story, told through inter-titles, about the tragic love story of Carmen. <br /><br />Carmen is sent by a band of gypsies (\"A band who put the GYP in gypsy.\"), to seduce a Spanish officer so they can pull off their smuggling operation. It\\'s a clever, Chaplinesque band of criminals, the leader of whom, Lillas Pastia, has \"spent 50 years learning to steal, thinking he might be offered a job in politics.\" <br /><br />On a side note, I\\'ve seen some almost misogynistic messages and jokes in some of Chaplin\\'s earlier work, but probably none quite as overt as in this one. Near the beginning of the movie, as the band of gypsies are traveling, there is a scene where the mules and women are loading, and an inter-title explains that \"the mules are the ones with long ears.\" In case you couldn\\'t tell, I guess. <br /><br />Chaplin plays the part of Don Jose, the hapless officer who is to be seduced by Carmen. He is described as \"a brave soldier and lover of women.\" Not exactly a stretch for Chaplin who removed any doubt about his ability to play a convincing comic soldier a few years later in the brilliant Shoulder Arms. And of course, he didn\\'t have to act about being a lover of women.<br /><br />What is different here, of course, is his polished military uniform and straight-backed disciplinary manner, interspersed, of course, with some of his traditional slap-stick moves. He strikes me as a little guy in a position of authority, struggling to maintain the respect of his subordinates by exerting a gruff, stolid exterior.<br /><br />Soon Carmen enters (\"Loved by all men under the age of 96\\x85\"), and she immediately begins flirting with Charlie. I should mention that for a good majority of the movie, it is surprisingly faithful to the original story, which was full of jealousy and tragedy. Chaplin is strangely convincing as a jealous lover, able to evoke a jealous passion that I\\'ve never seen from him. There\\'s at least one scene where he is genuinely a little scary. <br /><br />Chaplin has some great sight gags in the movie, like a hilarious table dance and some classic sword fighting near the end. And his boyish charm and the role of a soldier is also definitely a winning combination, although there is another peculiar stunt involving a group of men pushing a huge door back and forth that wasn\\'t very effective to begin with but just kept going on and on and on, probably about five times longer than it was worth. Although it was interesting that when it finally fell over it clearly was revealed as a movie prop. I always appreciate such glimpses at the old movie sets.<br /><br />The end of the film is it\\'s strongest part. It bears striking resemblance to Romeo and Juliet, but just when you think that Chaplin is going to conduct a major thematic experiment by diverging distantly from his traditional style, there is a hilarious twist that is as vintage Chaplin as anything I\\'ve ever seen. Nice work!<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_log_probs = model(example_input[None,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7103437e-36, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(sentiment_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}